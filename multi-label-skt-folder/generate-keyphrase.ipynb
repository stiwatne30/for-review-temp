{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f7597d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import guidedlda\n",
    "import time\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "import string\n",
    "\n",
    "\"\"\"BQ imports\"\"\"\n",
    "from google.cloud import bigquery\n",
    "client = bigquery.Client()\n",
    "\n",
    "from itertools import chain\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7c47a10",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_lg==2.3.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.3.1/en_core_web_lg-2.3.1.tar.gz (782.7 MB)\n",
      "\u001b[K     |████████████████████████▎       | 594.0 MB 205.6 MB/s eta 0:00:01"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 782.7 MB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from en_core_web_lg==2.3.1) (2.3.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (7.4.5)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.5)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (58.1.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.21.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.26.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (4.62.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (0.8.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (3.0.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (0.7.4)\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (4.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (3.10.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (3.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.0.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.26.7)\n",
      "Building wheels for collected packages: en-core-web-lg\n",
      "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.3.1-py3-none-any.whl size=782936122 sha256=636e499a4975538320c176783bf75e01b692556d66a32082b25abc4fff1bfe13\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-cybpgaho/wheels/41/75/77/c4a98e18b2c317a2a13931cbbea7e3ca7f3a21efc36adc1d71\n",
      "Successfully built en-core-web-lg\n",
      "Installing collected packages: en-core-web-lg\n",
      "Successfully installed en-core-web-lg-2.3.1\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4f2309f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy==2.3.3\n",
      "  Downloading spacy-2.3.3-cp37-cp37m-manylinux2014_x86_64.whl (10.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.4 MB 5.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cymem<2.1.0,>=2.0.2\n",
      "  Using cached cymem-2.0.5-cp37-cp37m-manylinux2014_x86_64.whl (35 kB)\n",
      "Collecting srsly<1.1.0,>=1.0.2\n",
      "  Downloading srsly-1.0.5-cp37-cp37m-manylinux2014_x86_64.whl (184 kB)\n",
      "\u001b[K     |████████████████████████████████| 184 kB 133.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy==2.3.3) (1.0.5)\n",
      "Collecting plac<1.2.0,>=0.9.6\n",
      "  Downloading plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Using cached blis-0.7.4-cp37-cp37m-manylinux2014_x86_64.whl (9.8 MB)\n",
      "Collecting catalogue<1.1.0,>=0.0.7\n",
      "  Downloading catalogue-1.0.0-py2.py3-none-any.whl (7.7 kB)\n",
      "Collecting thinc<7.5.0,>=7.4.1\n",
      "  Downloading thinc-7.4.5-cp37-cp37m-manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 100.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wasabi<1.1.0,>=0.4.0\n",
      "  Using cached wasabi-0.8.2-py3-none-any.whl (23 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Using cached preshed-3.0.5-cp37-cp37m-manylinux2014_x86_64.whl (126 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy==2.3.3) (58.1.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy==2.3.3) (1.21.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy==2.3.3) (2.26.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy==2.3.3) (4.62.3)\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.3.3) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.3.3) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.3.3) (3.10.0.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.3) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.3) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.3) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.3) (3.2)\n",
      "Installing collected packages: cymem, wasabi, srsly, preshed, plac, catalogue, blis, thinc, spacy\n",
      "Successfully installed blis-0.7.4 catalogue-1.0.0 cymem-2.0.5 plac-1.1.3 preshed-3.0.5 spacy-2.3.3 srsly-1.0.5 thinc-7.4.5 wasabi-0.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy==2.3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3db6628",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytextrank==2.0.3\n",
      "  Downloading pytextrank-2.0.3-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.7/site-packages (from pytextrank==2.0.3) (2.5)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.17-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.7/site-packages (from pytextrank==2.0.3) (2.3.3)\n",
      "Collecting coverage\n",
      "  Downloading coverage-5.5-cp37-cp37m-manylinux2010_x86_64.whl (242 kB)\n",
      "\u001b[K     |████████████████████████████████| 242 kB 4.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx->pytextrank==2.0.3) (5.0.9)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy->pytextrank==2.0.3) (1.1.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy->pytextrank==2.0.3) (58.1.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy->pytextrank==2.0.3) (0.7.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy->pytextrank==2.0.3) (2.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy->pytextrank==2.0.3) (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy->pytextrank==2.0.3) (1.21.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy->pytextrank==2.0.3) (1.0.5)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy->pytextrank==2.0.3) (7.4.5)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy->pytextrank==2.0.3) (1.0.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy->pytextrank==2.0.3) (0.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy->pytextrank==2.0.3) (2.26.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy->pytextrank==2.0.3) (3.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy->pytextrank==2.0.3) (4.62.3)\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy->pytextrank==2.0.3) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy->pytextrank==2.0.3) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy->pytextrank==2.0.3) (3.10.0.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy->pytextrank==2.0.3) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy->pytextrank==2.0.3) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy->pytextrank==2.0.3) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy->pytextrank==2.0.3) (2.0.6)\n",
      "Installing collected packages: graphviz, coverage, pytextrank\n",
      "Successfully installed coverage-5.5 graphviz-0.17 pytextrank-2.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pytextrank==2.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4b8842b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fuzzywuzzy==0.18.0\n",
      "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
      "Installing collected packages: fuzzywuzzy\n",
      "Successfully installed fuzzywuzzy-0.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install fuzzywuzzy==0.18.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf3f4501",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-Levenshtein==0.12.1\n",
      "  Downloading python-Levenshtein-0.12.1.tar.gz (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 3.3 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from python-Levenshtein==0.12.1) (58.1.0)\n",
      "Building wheels for collected packages: python-Levenshtein\n",
      "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.1-cp37-cp37m-linux_x86_64.whl size=178235 sha256=e2474be3e886959b65b0dafd792211df71a347d51762888ddca2f13132d8e398\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/20/d6/58/279b0443284b2e509e83f6cde4cdb270e2df46db3692c6e667\n",
      "Successfully built python-Levenshtein\n",
      "Installing collected packages: python-Levenshtein\n",
      "Successfully installed python-Levenshtein-0.12.1\n"
     ]
    }
   ],
   "source": [
    "!pip install python-Levenshtein==0.12.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "957e74fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10078, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>natid</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>category</th>\n",
       "      <th>tier1</th>\n",
       "      <th>tier2</th>\n",
       "      <th>summary</th>\n",
       "      <th>clean_summary</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blogandpostid/blog/post/50808-607eda2d97a5b000...</td>\n",
       "      <td>2021-04-20</td>\n",
       "      <td>Personal Finance</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Real Estate Renting and Leasing</td>\n",
       "      <td>WeWork To Accept Crypto—And Will Pay Its Landl...</td>\n",
       "      <td>wework accept crypto pay landlords crypto. top...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blogandpostid/blog/post/4587-60d354bc9690ca000...</td>\n",
       "      <td>2021-06-23</td>\n",
       "      <td>Food and Drink</td>\n",
       "      <td>Travel</td>\n",
       "      <td>Travel Type</td>\n",
       "      <td>Celebrate The Lodge At Woodloch’s 15-Year Anni...</td>\n",
       "      <td>celebrate lodge woodloch's 15-year anniversary...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blogandpostid/blog/post/3113-5f526f97559f59000...</td>\n",
       "      <td>2020-09-04</td>\n",
       "      <td>Music and Audio</td>\n",
       "      <td>Music and Audio</td>\n",
       "      <td>Hip Hop Music</td>\n",
       "      <td>Cardi B And Megan Thee Stallion Both Earn Thei...</td>\n",
       "      <td>cardi b megan thee stallion earn no. 1 hit you...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blogandpostid/blog/post/5259-6015f002c7824f000...</td>\n",
       "      <td>2021-02-09</td>\n",
       "      <td>Travel</td>\n",
       "      <td>Shopping</td>\n",
       "      <td>Gifts and Greetings Cards</td>\n",
       "      <td>Valentine’s Day Gift Guide: The Most Romantic ...</td>\n",
       "      <td>valentine's day gift guide: romantic hotel pac...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blogandpostid/blog/post/4983-5f8064d69a4142000...</td>\n",
       "      <td>2020-10-14</td>\n",
       "      <td>Shopping</td>\n",
       "      <td>Shopping</td>\n",
       "      <td>Sales and Promotions</td>\n",
       "      <td>The Best Prime Day Bike Deals For Saving Big o...</td>\n",
       "      <td>best prime day bike deals saving big bicycles ...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               natid    pub_date  \\\n",
       "0  blogandpostid/blog/post/50808-607eda2d97a5b000...  2021-04-20   \n",
       "1  blogandpostid/blog/post/4587-60d354bc9690ca000...  2021-06-23   \n",
       "2  blogandpostid/blog/post/3113-5f526f97559f59000...  2020-09-04   \n",
       "3  blogandpostid/blog/post/5259-6015f002c7824f000...  2021-02-09   \n",
       "4  blogandpostid/blog/post/4983-5f8064d69a4142000...  2020-10-14   \n",
       "\n",
       "           category            tier1                            tier2  \\\n",
       "0  Personal Finance      Real Estate  Real Estate Renting and Leasing   \n",
       "1    Food and Drink           Travel                      Travel Type   \n",
       "2   Music and Audio  Music and Audio                    Hip Hop Music   \n",
       "3            Travel         Shopping        Gifts and Greetings Cards   \n",
       "4          Shopping         Shopping             Sales and Promotions   \n",
       "\n",
       "                                             summary  \\\n",
       "0  WeWork To Accept Crypto—And Will Pay Its Landl...   \n",
       "1  Celebrate The Lodge At Woodloch’s 15-Year Anni...   \n",
       "2  Cardi B And Megan Thee Stallion Both Earn Thei...   \n",
       "3  Valentine’s Day Gift Guide: The Most Romantic ...   \n",
       "4  The Best Prime Day Bike Deals For Saving Big o...   \n",
       "\n",
       "                                       clean_summary  label  \n",
       "0  wework accept crypto pay landlords crypto. top...      7  \n",
       "1  celebrate lodge woodloch's 15-year anniversary...     23  \n",
       "2  cardi b megan thee stallion earn no. 1 hit you...     12  \n",
       "3  valentine's day gift guide: romantic hotel pac...     13  \n",
       "4  best prime day bike deals saving big bicycles ...     13  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_pickle(\"./data/preprocess_mnet_train.pkl\")\n",
    "\n",
    "train.drop_duplicates('natid', keep='first', inplace=True)\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c22e060a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Business', 'Economy', 'Industries']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(train[train.tier1=='Business and Finance'].tier2.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86eaf610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1258, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>natid</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>category</th>\n",
       "      <th>tier1</th>\n",
       "      <th>tier2</th>\n",
       "      <th>summary</th>\n",
       "      <th>clean_summary</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blogandpostid/blog/post/3541-60eb91d76f189c000...</td>\n",
       "      <td>2021-07-12</td>\n",
       "      <td>Movies</td>\n",
       "      <td>Movies</td>\n",
       "      <td>Indie and Arthouse Movies</td>\n",
       "      <td>What Will The Movie Industry Look Like After C...</td>\n",
       "      <td>movie industry look like covid?. movie industr...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blogandpostid/blog/post/7380-5f7a952000e768000...</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>Video Gaming</td>\n",
       "      <td>Video Gaming</td>\n",
       "      <td>Video Game Genres</td>\n",
       "      <td>A YouTuber Made An ‘Among Us’ Mode In ‘Overwat...</td>\n",
       "      <td>youtuber us' mode overwatch' looks fantastic. ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blogandpostid/blog/post/50373-5fcfe6475a1f9400...</td>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>News and Politics</td>\n",
       "      <td>News and Politics</td>\n",
       "      <td>Politics</td>\n",
       "      <td>Rudy Giuliani Says He’s ‘Doing Fine’ With Covi...</td>\n",
       "      <td>rudy giuliani says fine' covid, hopes released...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blogandpostid/blog/post/25-607d3d189d9fd30006d...</td>\n",
       "      <td>2021-04-19</td>\n",
       "      <td>Technology and Computing</td>\n",
       "      <td>Personal Finance</td>\n",
       "      <td>Personal Investing</td>\n",
       "      <td>Will Apple Stock’s Q2 Results Beat Consensus?....</td>\n",
       "      <td>apple stock's q2 results beat consensus?. appl...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blogandpostid/blog/post/6937-60b6f3feff8c53000...</td>\n",
       "      <td>2021-06-02</td>\n",
       "      <td>Movies</td>\n",
       "      <td>Movies</td>\n",
       "      <td>Documentary Movies</td>\n",
       "      <td>Ava DuVernay’s Array Film Collective Partners ...</td>\n",
       "      <td>ava duvernay's array film collective partners ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               natid    pub_date  \\\n",
       "0  blogandpostid/blog/post/3541-60eb91d76f189c000...  2021-07-12   \n",
       "1  blogandpostid/blog/post/7380-5f7a952000e768000...  2020-10-05   \n",
       "2  blogandpostid/blog/post/50373-5fcfe6475a1f9400...  2020-12-08   \n",
       "3  blogandpostid/blog/post/25-607d3d189d9fd30006d...  2021-04-19   \n",
       "4  blogandpostid/blog/post/6937-60b6f3feff8c53000...  2021-06-02   \n",
       "\n",
       "                   category              tier1                      tier2  \\\n",
       "0                    Movies             Movies  Indie and Arthouse Movies   \n",
       "1              Video Gaming       Video Gaming          Video Game Genres   \n",
       "2         News and Politics  News and Politics                   Politics   \n",
       "3  Technology and Computing   Personal Finance         Personal Investing   \n",
       "4                    Movies             Movies         Documentary Movies   \n",
       "\n",
       "                                             summary  \\\n",
       "0  What Will The Movie Industry Look Like After C...   \n",
       "1  A YouTuber Made An ‘Among Us’ Mode In ‘Overwat...   \n",
       "2  Rudy Giuliani Says He’s ‘Doing Fine’ With Covi...   \n",
       "3  Will Apple Stock’s Q2 Results Beat Consensus?....   \n",
       "4  Ava DuVernay’s Array Film Collective Partners ...   \n",
       "\n",
       "                                       clean_summary  label  \n",
       "0  movie industry look like covid?. movie industr...      2  \n",
       "1  youtuber us' mode overwatch' looks fantastic. ...     10  \n",
       "2  rudy giuliani says fine' covid, hopes released...      0  \n",
       "3  apple stock's q2 results beat consensus?. appl...     21  \n",
       "4  ava duvernay's array film collective partners ...      2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_pickle(\"./data/preprocess_mnet_test.pkl\")\n",
    "test.drop_duplicates('natid', keep='first', inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76213279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before (11336, 8)\n",
      "After (11046, 8)\n"
     ]
    }
   ],
   "source": [
    "full = pd.concat([train, test])\n",
    "print(\"Before\", full.shape)\n",
    "\n",
    "full.drop_duplicates('natid', keep='first', inplace=True)\n",
    "full.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"After\", full.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ba123a",
   "metadata": {},
   "source": [
    "* Get articles which have keyphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46955e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (77287, 4)\n"
     ]
    }
   ],
   "source": [
    "sql= \"\"\"\n",
    "    SELECT \n",
    "        * \n",
    "    FROM \n",
    "        `api-project-901373404215.keyphrase_extraction.forbes_keyphrases` \n",
    "    \"\"\"\n",
    "\n",
    "# Send the query to the api and return a df\n",
    "keyphrase_df = client.query(sql).to_dataframe()\n",
    "\n",
    "print(\"Shape: \", keyphrase_df.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c48f83e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>natid</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>category</th>\n",
       "      <th>tier1</th>\n",
       "      <th>tier2</th>\n",
       "      <th>summary</th>\n",
       "      <th>clean_summary</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blogandpostid/blog/post/50276-60f734ce80505100...</td>\n",
       "      <td>2021-07-20</td>\n",
       "      <td>News and Politics</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Golf</td>\n",
       "      <td>Trump Says Cheney Challengers Will Vie For His...</td>\n",
       "      <td>trump says cheney challengers vie endorsement ...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blogandpostid/blog/post/50769-6120124cfd4e7600...</td>\n",
       "      <td>2021-08-20</td>\n",
       "      <td>News and Politics</td>\n",
       "      <td>Family and Relationships</td>\n",
       "      <td>Parenting</td>\n",
       "      <td>Baby Passed To U.S. Troops Over Kabul Airport ...</td>\n",
       "      <td>baby passed usa troops kabul airport fence reu...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blogandpostid/blog/post/4983-5fad72b4d076a5000...</td>\n",
       "      <td>2020-11-27</td>\n",
       "      <td>Shopping</td>\n",
       "      <td>Shopping</td>\n",
       "      <td>Sales and Promotions</td>\n",
       "      <td>The Best Black Friday Couch Deals: Top Furnitu...</td>\n",
       "      <td>best black friday couch deals: furniture sites...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               natid    pub_date  \\\n",
       "0  blogandpostid/blog/post/50276-60f734ce80505100...  2021-07-20   \n",
       "1  blogandpostid/blog/post/50769-6120124cfd4e7600...  2021-08-20   \n",
       "2  blogandpostid/blog/post/4983-5fad72b4d076a5000...  2020-11-27   \n",
       "\n",
       "            category                     tier1                 tier2  \\\n",
       "0  News and Politics                    Sports                  Golf   \n",
       "1  News and Politics  Family and Relationships             Parenting   \n",
       "2           Shopping                  Shopping  Sales and Promotions   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Trump Says Cheney Challengers Will Vie For His...   \n",
       "1  Baby Passed To U.S. Troops Over Kabul Airport ...   \n",
       "2  The Best Black Friday Couch Deals: Top Furnitu...   \n",
       "\n",
       "                                       clean_summary  label  \n",
       "0  trump says cheney challengers vie endorsement ...     18  \n",
       "1  baby passed usa troops kabul airport fence reu...     11  \n",
       "2  best black friday couch deals: furniture sites...     13  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking to make sure we are not processing any articles already in the forbes_keyphrases table\n",
    "\n",
    "# df = full[~full.natid.isin(keyphrase_df.naturalid)]\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "# df.shape\n",
    "\n",
    "# 3 got left out somehow. processing them\n",
    "df = train[~train.natid.isin(all_kps.natid)]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d93a9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import html.parser\n",
    "import unicodedata\n",
    "import spacy\n",
    "import pytextrank \n",
    "\n",
    "STOP_WORDS = pd.read_pickle('./data/forbes_stop_words.pkl')\n",
    "\n",
    "# Contraction dictionary\n",
    "\n",
    "contraction_dict_file = './data/contraction_dictionary.pkl'\n",
    "c_dict = pd.read_pickle(contraction_dict_file)\n",
    "# Compiling the contraction dict\n",
    "c_re = re.compile('(%s)' % '|'.join(c_dict.keys()))\n",
    "\n",
    "def listToString(s):  \n",
    "    str1 = \" \" \n",
    "    return (str1.join(s)) \n",
    "\n",
    "# Function to expand contractions\n",
    "def expandContractions(text):\n",
    "    def replace(match):\n",
    "        return c_dict[match.group(0)]\n",
    "    return c_re.sub(replace, text)\n",
    "\n",
    "# Function to remove unicode\n",
    "def normalize_unicode(input_str):\n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str) # replaces accents by converting to byte literal and then decoding to utf-8.\n",
    "    only_ascii = nfkd_form.encode('ASCII', 'ignore')\n",
    "    return only_ascii.decode(\"utf-8\")  \n",
    "\n",
    "# Function to remove the html\n",
    "class HTMLTextExtractor(html.parser.HTMLParser):\n",
    "    def __init__(self):\n",
    "        super(HTMLTextExtractor, self).__init__()\n",
    "        self.result = []\n",
    "    def handle_data(self, d):\n",
    "        self.result.append(d)\n",
    "    def get_text(self):\n",
    "        return ''.join(self.result)\n",
    "\n",
    "def html_to_text(html):\n",
    "    s = HTMLTextExtractor()\n",
    "    s.feed(html)\n",
    "    return s.get_text()\n",
    "\n",
    "def remove_html(text):\n",
    "    text = str(text)\n",
    "    string = re.sub('<[^<]+?>', ' ', text)\n",
    "    string = html_to_text(string)\n",
    "    string = re.sub('’', \"'\", string) \n",
    "    string = re.sub(r'[^\\x00-\\x7F]+', ' ', string) # [^\\x00-\\x7F]+ searches for all non-ASCII values\n",
    "    string = re.sub(r'\\[.*?\\]', ' ', string) # escape special characters mentioned inside []\n",
    "    string = string.replace('\\r', '  ')\n",
    "    string = string.replace('\\n', '  ')\n",
    "    string = re.sub(' +', ' ', string)\n",
    "    return string\n",
    "\n",
    "# Function to remove newline character\n",
    "def remove_newline(string):\n",
    "    string = string.replace('\\r', '') #remove carriage return\n",
    "    return string.replace('\\n', '') #remove newline\n",
    "\n",
    "\n",
    "# -------------------------------- SPACY TEXTRANK --------------------------------\n",
    "try:\n",
    "    nlp = spacy.load('en_core_web_lg')\n",
    "except OSError as e:\n",
    "    print(e)\n",
    "    print('Downloading spacy en_core_web_lg language model')\n",
    "    from spacy.cli import download\n",
    "    download('en_core_web_lg')\n",
    "    nlp = spacy.load('en_core_web_lg')\n",
    "    \n",
    "tr = pytextrank.TextRank()\n",
    "nlp.add_pipe(tr.PipelineComponent, name='textrank', last=True)\n",
    "\n",
    "def spacy_textrank(text):\n",
    "    num_words = int(len(word_tokenize(text)))\n",
    "    if(num_words <= 100):\n",
    "        num_keywords = int(num_words * 0.2)\n",
    "    elif (num_words > 100 and num_words <= 400):\n",
    "        num_keywords =  int(num_words * 0.1)\n",
    "    elif (num_words > 400 and num_words <= 1000):\n",
    "        num_keywords =  int(num_words * 0.04)\n",
    "    elif (num_words > 1000 and num_words <= 3000):\n",
    "        num_keywords =  min(int(num_words * 0.02), 40)\n",
    "    else:\n",
    "        num_keywords = min(int(num_words * 0.01), 40)\n",
    "        \n",
    "    spacy_textrank = []\n",
    "    doc = nlp(text)\n",
    "    for p in doc._.phrases[:num_keywords]:\n",
    "        spacy_textrank.append(p.text)\n",
    "\n",
    "    return spacy_textrank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520ea87a",
   "metadata": {},
   "source": [
    "* Pre-process article text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc63b51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>natid</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>category</th>\n",
       "      <th>tier1</th>\n",
       "      <th>tier2</th>\n",
       "      <th>summary</th>\n",
       "      <th>clean_summary</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blogandpostid/blog/post/50276-60f734ce80505100...</td>\n",
       "      <td>2021-07-20</td>\n",
       "      <td>News and Politics</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Golf</td>\n",
       "      <td>Trump Says Cheney Challengers Will Vie For His...</td>\n",
       "      <td>trump says cheney challengers vie endorsement ...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blogandpostid/blog/post/50769-6120124cfd4e7600...</td>\n",
       "      <td>2021-08-20</td>\n",
       "      <td>News and Politics</td>\n",
       "      <td>Family and Relationships</td>\n",
       "      <td>Parenting</td>\n",
       "      <td>Baby Passed To U.S. Troops Over Kabul Airport ...</td>\n",
       "      <td>baby passed usa troops kabul airport fence reu...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blogandpostid/blog/post/4983-5fad72b4d076a5000...</td>\n",
       "      <td>2020-11-27</td>\n",
       "      <td>Shopping</td>\n",
       "      <td>Shopping</td>\n",
       "      <td>Sales and Promotions</td>\n",
       "      <td>The Best Black Friday Couch Deals: Top Furnitu...</td>\n",
       "      <td>best black friday couch deals: furniture sites...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               natid    pub_date  \\\n",
       "0  blogandpostid/blog/post/50276-60f734ce80505100...  2021-07-20   \n",
       "1  blogandpostid/blog/post/50769-6120124cfd4e7600...  2021-08-20   \n",
       "2  blogandpostid/blog/post/4983-5fad72b4d076a5000...  2020-11-27   \n",
       "\n",
       "            category                     tier1                 tier2  \\\n",
       "0  News and Politics                    Sports                  Golf   \n",
       "1  News and Politics  Family and Relationships             Parenting   \n",
       "2           Shopping                  Shopping  Sales and Promotions   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Trump Says Cheney Challengers Will Vie For His...   \n",
       "1  Baby Passed To U.S. Troops Over Kabul Airport ...   \n",
       "2  The Best Black Friday Couch Deals: Top Furnitu...   \n",
       "\n",
       "                                       clean_summary  label  \n",
       "0  trump says cheney challengers vie endorsement ...     18  \n",
       "1  baby passed usa troops kabul airport fence reu...     11  \n",
       "2  best black friday couch deals: furniture sites...     13  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7dd12d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial keyphrases generation time in mins:  0.006176706155141195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# Remove html, normalize unicode\n",
    "df['clean_body'] = df['summary'].astype(str)\n",
    "df['clean_body'] = df['clean_body'].apply(remove_newline).astype(str)\n",
    "df['clean_body'] = df['clean_body'].apply(expandContractions)\n",
    "df['clean_body'] = df['clean_body'].apply(normalize_unicode)\n",
    "df['clean_body'] = df['clean_body'].apply(remove_html).str.strip()\n",
    "df['clean_body'] = df['clean_body'].apply(lambda x: re.sub(r\"<[^>]*>\", \" \", x)) \n",
    "\n",
    "# Proprocess and clean\n",
    "df['clean_body'] = df['clean_body'].str.lower()\n",
    "df['clean_body'] = df['clean_body'].apply(lambda x: re.sub(r'\\d+', '', x)) # remove numbers\n",
    "df['clean_body'] = df['clean_body'].str.replace('%','') # remove '%' sign\n",
    "df['clean_body'] = df['clean_body'].str.replace('covid- ','covid-19') # patch-fix an important word\n",
    "df['clean_body'] =  df['clean_body'].replace('\\s+', ' ', regex=True) # remove more than 1 space in between words\n",
    "\n",
    "start = time.time()\n",
    "df[\"spacytextrank_keywords\"] = df[\"clean_body\"].apply(lambda x: spacy_textrank(x)) \n",
    "end = time.time()\n",
    "print(\"Initial keyphrases generation time in mins: \", (end - start)/60) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ecbe9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after stopw ['anti-trump rep. liz cheney', 'cheney challengers', 'rep. bennie thompson', 'rep. jamie raskin', 'cheney', 'liz cheney', 'wyoming state sen. anthony bouchard', 'cheney', 'donald trump', 'sen. lisa murkowski', 'former president donald trump', 'one anti-cheney candidate', 'republican challenging rep. anthony gonzalez', 'house speaker nancy pelosi', 'new jersey golf club', 'new jersey', 'wyoming']\n",
      "after google ner ['anti-trump rep. liz cheney', 'cheney challengers', 'rep. bennie thompson', 'rep. jamie raskin', 'wyoming state sen. anthony bouchard', 'sen. lisa murkowski', 'former president donald trump', 'one anti-cheney candidate', 'republican challenging rep. anthony gonzalez', 'house speaker nancy pelosi', 'new jersey golf club']\n",
      "after similar words ['anti-trump rep. liz cheney', 'cheney challengers', 'rep. bennie thompson', 'rep. jamie raskin', 'wyoming state sen. anthony bouchard', 'sen. lisa murkowski', 'former president donald trump', 'one anti-cheney candidate', 'republican challenging rep. anthony gonzalez', 'house speaker nancy pelosi', 'new jersey golf club']\n",
      "after stopw ['u.s. troops', 'u.s. marines', 'u.s. citizens', 'u.s. forces', 'kabul airport fence', 'u.s. military controls', 'pentagon spokesperson john kirby', 'marine corps spokesperson jim stenger', 'u.s. militarys perimeter', 'friday', 'u.s. military', 'kabul evacuations', 'president joe biden', 'kabuls hamid karzai international airport', 'joe biden', 'kabul', 'afghanistan']\n",
      "after google ner ['u.s. troops', 'u.s. marines', 'u.s. citizens', 'u.s. forces', 'kabul airport fence', 'u.s. military controls', 'pentagon spokesperson john kirby', 'marine corps spokesperson jim stenger', 'u.s. militarys perimeter', 'u.s. military', 'kabul evacuations', 'president joe biden', 'kabuls hamid karzai international airport']\n",
      "after similar words ['u.s. troops', 'u.s. marines', 'u.s. citizens', 'u.s. forces', 'kabul airport fence', 'u.s. military controls', 'pentagon spokesperson john kirby', 'marine corps spokesperson jim stenger', 'u.s. militarys perimeter', 'kabul evacuations', 'president joe biden', 'kabuls hamid karzai international airport']\n",
      "after stopw ['black friday couch deals', 'black friday deals', 'weather black friday couch deals', 'main black friday couch deals', 'allmodern black friday couch deals', 'burrow black friday couch deals', 'black friday sale', 'amazon black friday couch deals amazons black friday sale', 'black friday couch deals', 'target black friday couch deals target', 'black friday sale', 'article black friday couch deals articles', 'pottery barn black friday couch deals', 'target black friday deals', 'black friday couch deals rove concepts', 'black friday', 'allmoderns black friday sale', 'hayneedles black friday sale', 'ballards black friday sale', 'aptb black friday couch deals', 'macys black friday couch deals macys', 'pottery barns black friday sale']\n",
      "after google ner ['black friday couch deals', 'black friday deals', 'weather black friday couch deals', 'main black friday couch deals', 'allmodern black friday couch deals', 'burrow black friday couch deals', 'black friday sale', 'amazon black friday couch deals amazons black friday sale', 'black friday couch deals', 'target black friday couch deals target', 'black friday sale', 'article black friday couch deals articles', 'pottery barn black friday couch deals', 'target black friday deals', 'black friday couch deals rove concepts', 'allmoderns black friday sale', 'hayneedles black friday sale', 'ballards black friday sale', 'aptb black friday couch deals', 'macys black friday couch deals macys', 'pottery barns black friday sale']\n",
      "after similar words ['target black friday deals', 'black friday couch deals rove concepts', 'allmoderns black friday sale', 'hayneedles black friday sale', 'ballards black friday sale', 'macys black friday couch deals macys', 'pottery barns black friday sale']\n",
      "Keyword cleaning time in mins:  0.0775274395942688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from collections import OrderedDict\n",
    "from fuzzywuzzy import process, fuzz\n",
    "\n",
    "# ---------Clean keywords---------\n",
    "\n",
    "# read ner_forbes table\n",
    "sql = \"\"\"\n",
    "    SELECT\n",
    "        distinct(token), tag \n",
    "    FROM `api-project-901373404215.ner.ner_forbes` \n",
    "    ORDER BY token \n",
    "    \"\"\"\n",
    "# Send the query to the api and return a df\n",
    "google_ner = client.query(sql).to_dataframe()\n",
    "google_ner = google_ner[google_ner[\"token\"].apply(lambda x: len(x)>1)]\n",
    "\n",
    "start = time.time()\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "clean_keys = []\n",
    "for index, row in df.iterrows(): \n",
    "    # remove pattern STOP WORDS\n",
    "    pattern = re.compile(\"\\\\b(the|only|other|their|these|our|her|his|such|some|many|most|my|his|all|several|people|earlier|an|your|its|enough|nice|this|$|more|how|how much|topline|further reading|key facts|key background|crucial quote|yesterdays|related reading|morning|evening)\\\\W\", re.I)\n",
    "    inter_list = [pattern.sub(\"\", x) for x in row[\"spacytextrank_keywords\"]]\n",
    "    # remove starting \"a\"\n",
    "    pattern_a = re.compile(r'^a\\s', re.I)\n",
    "    inter_list = [pattern_a.sub(\"\", x) for x in inter_list]\n",
    "    # remove STOP WORDS\n",
    "    inter_list = [x for x in inter_list if x not in STOP_WORDS]\n",
    "    \n",
    "    print(\"after stopw\", inter_list)\n",
    "\n",
    "    # remove NERs from ner_forbes\n",
    "    inter_list = [x for x in inter_list if x not in list(google_ner.token)]\n",
    "    \n",
    "    print(\"after google ner\", inter_list)\n",
    "\n",
    "    # remove SPACY NER words\n",
    "    ner_words_to_remove = []\n",
    "    for elem in inter_list:\n",
    "        doc1 = nlp(elem)\n",
    "        for entity in doc1.ents:\n",
    "            # keeping 'ORG' out for now\n",
    "            if entity.label_ in ('GPE', 'LOC', 'FAC', 'PERSON',  'DATE'):    \n",
    "                ner_words_to_remove.append(elem)\n",
    "\n",
    "    inter_list = [x for x in inter_list if x not in ner_words_to_remove]\n",
    "    \n",
    "    print(\"after spacy ner\", inter_list)\n",
    "\n",
    "    # remove subset-based similar words - e.g. 'pcr tests' and 'tests' then 'tests' will be removed\n",
    "    inter_list = [i for i in inter_list if not any(i in x and i!=x for x in inter_list)]\n",
    "    if(len(inter_list)>15):\n",
    "        # remove similar words using fuzzy match with score>85 - e.g. 'student loans' and 'student loan debt'\n",
    "        matches_to_remove = []\n",
    "        for i in range(len(inter_list)):\n",
    "            process_match = process.extract(inter_list[i], inter_list, scorer=fuzz.partial_ratio) # match every word with other word\n",
    "            filter_match = [x for x in process_match if x[1]>85 and x[1]<100] \n",
    "            matches_to_remove.append([x[0] for x in filter_match])\n",
    "        matches_to_remove_list = list(set(list(chain(*matches_to_remove))))\n",
    "        inter_list = [x for x in inter_list if x not in matches_to_remove_list]\n",
    "    \n",
    "    print(\"after similar words\", inter_list)\n",
    "    # remove more than 1 space between words\n",
    "    inter_list = [re.sub(' +', ' ', x) for x in inter_list]\n",
    "    # remove extra whitespace\n",
    "    inter_list = [x.strip() for x in inter_list]\n",
    "    # remove empty or 1-letter words\n",
    "    inter_list = [x for x in inter_list if len(x)>1]\n",
    "    # de-duplicate\n",
    "    inter_list = list(OrderedDict.fromkeys(inter_list))\n",
    "    clean_keys.append(inter_list)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Keyword cleaning time in mins: \", (end - start)/60) \n",
    "\n",
    "# convert keyword lists to strings for saving in BigQuery table\n",
    "df['keyphrases'] = clean_keys #6.27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "526ca402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any empty keyphrase rows\n",
    "df = df[df['keyphrases'].apply(lambda x: len(x)>0)]\n",
    "df.keyphrases = df.keyphrases.astype(str)\n",
    "df.drop(\"spacytextrank_keywords\", axis=1, inplace=True)\n",
    "df.drop(\"clean_body\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de8acc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./mnet_test/new_keyphrases_last3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130143d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "129330b6",
   "metadata": {},
   "source": [
    "* Make datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0ae5640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10078, 8)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_pickle(\"./data/preprocess_mnet_train.pkl\")\n",
    "\n",
    "train.drop_duplicates('natid', keep='first', inplace=True)\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09d93835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1258, 8)\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_pickle(\"./data/preprocess_mnet_test.pkl\")\n",
    "test.drop_duplicates('natid', keep='first', inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41c5c3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before (11336, 8)\n",
      "After (11046, 8)\n",
      "Shape:  (77287, 4)\n"
     ]
    }
   ],
   "source": [
    "full = pd.concat([train, test])\n",
    "print(\"Before\", full.shape)\n",
    "\n",
    "full.drop_duplicates('natid', keep='first', inplace=True)\n",
    "full.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"After\", full.shape)\n",
    "\n",
    "sql= \"\"\"\n",
    "    SELECT \n",
    "        * \n",
    "    FROM \n",
    "        `api-project-901373404215.keyphrase_extraction.forbes_keyphrases` \n",
    "    \"\"\"\n",
    "\n",
    "# Send the query to the api and return a df\n",
    "keyphrase_df = client.query(sql).to_dataframe()\n",
    "\n",
    "print(\"Shape: \", keyphrase_df.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b31c515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# articles with keyphrases already generated\n",
    "\n",
    "bq_kps = pd.merge(full, \n",
    "                  keyphrase_df[['naturalid', 'keyphrases']], \n",
    "                  how=\"inner\", \n",
    "                  left_on=\"natid\", right_on=\"naturalid\")\n",
    "bq_kps.drop('naturalid', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2444086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>natid</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>category</th>\n",
       "      <th>tier1</th>\n",
       "      <th>tier2</th>\n",
       "      <th>summary</th>\n",
       "      <th>clean_summary</th>\n",
       "      <th>label</th>\n",
       "      <th>keyphrases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blogandpostid/blog/post/50808-607eda2d97a5b000...</td>\n",
       "      <td>2021-04-20</td>\n",
       "      <td>Personal Finance</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Real Estate Renting and Leasing</td>\n",
       "      <td>WeWork To Accept Crypto—And Will Pay Its Landl...</td>\n",
       "      <td>wework accept crypto pay landlords crypto. top...</td>\n",
       "      <td>7</td>\n",
       "      <td>[elon musks tesla, cryptocurrencies, private i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               natid    pub_date  \\\n",
       "0  blogandpostid/blog/post/50808-607eda2d97a5b000...  2021-04-20   \n",
       "\n",
       "           category        tier1                            tier2  \\\n",
       "0  Personal Finance  Real Estate  Real Estate Renting and Leasing   \n",
       "\n",
       "                                             summary  \\\n",
       "0  WeWork To Accept Crypto—And Will Pay Its Landl...   \n",
       "\n",
       "                                       clean_summary  label  \\\n",
       "0  wework accept crypto pay landlords crypto. top...      7   \n",
       "\n",
       "                                          keyphrases  \n",
       "0  [elon musks tesla, cryptocurrencies, private i...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bq_kps.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a640331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['elon musks tesla' 'cryptocurrencies' 'private investment' 'l ast week'\n",
      " 'nasdaq listing' 'latest payment app' 'memberships'\n",
      " 'mainstream acceptance' 'forbes) wework' 'usd coin' 'landlords'\n",
      " 'spac deal' 'wework membership']\n",
      "['prime day gaming laptop' 'best prime day chromebook deals chromebooks'\n",
      " 'professional laptops' 'great deals' 'prime day laptop deals'\n",
      " 'amazon prime day' 'best gaming laptops' 'acer chromebook'\n",
      " 'best smartphones']\n"
     ]
    }
   ],
   "source": [
    "print(bq_kps.head(1)['keyphrases'][0])\n",
    "print(bq_kps.tail(1)['keyphrases'][6742])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6213dad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_kps.keyphrases = bq_kps.keyphrases.apply(lambda x: ', '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "268c74be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>natid</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>category</th>\n",
       "      <th>tier1</th>\n",
       "      <th>tier2</th>\n",
       "      <th>summary</th>\n",
       "      <th>clean_summary</th>\n",
       "      <th>label</th>\n",
       "      <th>keyphrases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blogandpostid/blog/post/50808-607eda2d97a5b000...</td>\n",
       "      <td>2021-04-20</td>\n",
       "      <td>Personal Finance</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Real Estate Renting and Leasing</td>\n",
       "      <td>WeWork To Accept Crypto—And Will Pay Its Landl...</td>\n",
       "      <td>wework accept crypto pay landlords crypto. top...</td>\n",
       "      <td>7</td>\n",
       "      <td>elon musks tesla, cryptocurrencies, private in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               natid    pub_date  \\\n",
       "0  blogandpostid/blog/post/50808-607eda2d97a5b000...  2021-04-20   \n",
       "\n",
       "           category        tier1                            tier2  \\\n",
       "0  Personal Finance  Real Estate  Real Estate Renting and Leasing   \n",
       "\n",
       "                                             summary  \\\n",
       "0  WeWork To Accept Crypto—And Will Pay Its Landl...   \n",
       "\n",
       "                                       clean_summary  label  \\\n",
       "0  wework accept crypto pay landlords crypto. top...      7   \n",
       "\n",
       "                                          keyphrases  \n",
       "0  elon musks tesla, cryptocurrencies, private in...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bq_kps.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66be2a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elon musks tesla, cryptocurrencies, private investment, l ast week, nasdaq listing, latest payment app, memberships, mainstream acceptance, forbes) wework, usd coin, landlords, spac deal, wework membership\n",
      "prime day gaming laptop, best prime day chromebook deals chromebooks, professional laptops, great deals, prime day laptop deals, amazon prime day, best gaming laptops, acer chromebook, best smartphones\n"
     ]
    }
   ],
   "source": [
    "print(bq_kps.head(1)['keyphrases'][0])\n",
    "print(bq_kps.tail(1)['keyphrases'][6742])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18336467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4301, 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# articles with keyphrases newly generated above\n",
    "\n",
    "new_kps = pd.read_csv(\"./mnet_test/new_keyphrases.csv\")\n",
    "print(new_kps.shape)\n",
    "new_kps.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a59c2ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>natid</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>category</th>\n",
       "      <th>tier1</th>\n",
       "      <th>tier2</th>\n",
       "      <th>summary</th>\n",
       "      <th>clean_summary</th>\n",
       "      <th>label</th>\n",
       "      <th>keyphrases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blogandpostid/blog/post/3113-5f526f97559f59000...</td>\n",
       "      <td>2020-09-04</td>\n",
       "      <td>Music and Audio</td>\n",
       "      <td>Music and Audio</td>\n",
       "      <td>Hip Hop Music</td>\n",
       "      <td>Cardi B And Megan Thee Stallion Both Earn Thei...</td>\n",
       "      <td>cardi b megan thee stallion earn no. 1 hit you...</td>\n",
       "      <td>12</td>\n",
       "      <td>['cardi bs forthcoming sophomore full-length',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               natid    pub_date  \\\n",
       "0  blogandpostid/blog/post/3113-5f526f97559f59000...  2020-09-04   \n",
       "\n",
       "          category            tier1          tier2  \\\n",
       "0  Music and Audio  Music and Audio  Hip Hop Music   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Cardi B And Megan Thee Stallion Both Earn Thei...   \n",
       "\n",
       "                                       clean_summary  label  \\\n",
       "0  cardi b megan thee stallion earn no. 1 hit you...     12   \n",
       "\n",
       "                                          keyphrases  \n",
       "0  ['cardi bs forthcoming sophomore full-length',...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_kps.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "699bac8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cardi bs forthcoming sophomore full-length', 'first appearance', 'cardi bs highest-charting cut', 'frames', 'hip-hop return', 'five consecutive turns', 'latest single', 'release date']\n",
      "['new covid cases', 'positive cases', 'covid tracking project covid', 'case count', 'covid tracking project data', 'new coronavirus infections', 'highest number', 'hospitals', 'positive tests', 'massive upticks', ', new cases', 'masks', 'cold weather', 'national mask mandate']\n"
     ]
    }
   ],
   "source": [
    "print(new_kps.head(1)['keyphrases'][0])\n",
    "print(new_kps.tail(1)['keyphrases'][4300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4ece48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "new_kps.keyphrases = new_kps.keyphrases = new_kps.keyphrases.apply(ast.literal_eval).apply(lambda x: ', '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c93463d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>natid</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>category</th>\n",
       "      <th>tier1</th>\n",
       "      <th>tier2</th>\n",
       "      <th>summary</th>\n",
       "      <th>clean_summary</th>\n",
       "      <th>label</th>\n",
       "      <th>keyphrases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blogandpostid/blog/post/3113-5f526f97559f59000...</td>\n",
       "      <td>2020-09-04</td>\n",
       "      <td>Music and Audio</td>\n",
       "      <td>Music and Audio</td>\n",
       "      <td>Hip Hop Music</td>\n",
       "      <td>Cardi B And Megan Thee Stallion Both Earn Thei...</td>\n",
       "      <td>cardi b megan thee stallion earn no. 1 hit you...</td>\n",
       "      <td>12</td>\n",
       "      <td>cardi bs forthcoming sophomore full-length, fi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               natid    pub_date  \\\n",
       "0  blogandpostid/blog/post/3113-5f526f97559f59000...  2020-09-04   \n",
       "\n",
       "          category            tier1          tier2  \\\n",
       "0  Music and Audio  Music and Audio  Hip Hop Music   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Cardi B And Megan Thee Stallion Both Earn Thei...   \n",
       "\n",
       "                                       clean_summary  label  \\\n",
       "0  cardi b megan thee stallion earn no. 1 hit you...     12   \n",
       "\n",
       "                                          keyphrases  \n",
       "0  cardi bs forthcoming sophomore full-length, fi...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_kps.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e7cc6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardi bs forthcoming sophomore full-length, first appearance, cardi bs highest-charting cut, frames, hip-hop return, five consecutive turns, latest single, release date\n",
      "new covid cases, positive cases, covid tracking project covid, case count, covid tracking project data, new coronavirus infections, highest number, hospitals, positive tests, massive upticks, , new cases, masks, cold weather, national mask mandate\n"
     ]
    }
   ],
   "source": [
    "print(new_kps.head(1)['keyphrases'][0])\n",
    "print(new_kps.tail(1)['keyphrases'][4300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b19f5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# articles with keyphrases newly generated above\n",
    "\n",
    "last3_new_kps = pd.read_csv(\"./mnet_test/new_keyphrases_last3.csv\")\n",
    "print(last3_new_kps.shape)\n",
    "last3_new_kps.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dfe0ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>natid</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>category</th>\n",
       "      <th>tier1</th>\n",
       "      <th>tier2</th>\n",
       "      <th>summary</th>\n",
       "      <th>clean_summary</th>\n",
       "      <th>label</th>\n",
       "      <th>keyphrases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blogandpostid/blog/post/50276-60f734ce80505100...</td>\n",
       "      <td>2021-07-20</td>\n",
       "      <td>News and Politics</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Golf</td>\n",
       "      <td>Trump Says Cheney Challengers Will Vie For His...</td>\n",
       "      <td>trump says cheney challengers vie endorsement ...</td>\n",
       "      <td>18</td>\n",
       "      <td>['anti-trump rep. liz cheney', 'cheney challen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               natid    pub_date  \\\n",
       "0  blogandpostid/blog/post/50276-60f734ce80505100...  2021-07-20   \n",
       "\n",
       "            category   tier1 tier2  \\\n",
       "0  News and Politics  Sports  Golf   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Trump Says Cheney Challengers Will Vie For His...   \n",
       "\n",
       "                                       clean_summary  label  \\\n",
       "0  trump says cheney challengers vie endorsement ...     18   \n",
       "\n",
       "                                          keyphrases  \n",
       "0  ['anti-trump rep. liz cheney', 'cheney challen...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last3_new_kps.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b68c0963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anti-trump rep. liz cheney', 'cheney challengers', 'rep. bennie thompson', 'rep. jamie raskin', 'wyoming state sen. anthony bouchard', 'sen. lisa murkowski', 'former president donald trump', 'one anti-cheney candidate', 'republican challenging rep. anthony gonzalez', 'house speaker nancy pelosi', 'new jersey golf club']\n",
      "['target black friday deals', 'black friday couch deals rove concepts', 'allmoderns black friday sale', 'hayneedles black friday sale', 'ballards black friday sale', 'macys black friday couch deals macys', 'pottery barns black friday sale']\n"
     ]
    }
   ],
   "source": [
    "print(last3_new_kps.head(1)['keyphrases'][0])\n",
    "print(last3_new_kps.tail(1)['keyphrases'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72af224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "last3_new_kps.keyphrases = last3_new_kps.keyphrases.apply(ast.literal_eval).apply(lambda x: ', '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28bbf21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>natid</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>category</th>\n",
       "      <th>tier1</th>\n",
       "      <th>tier2</th>\n",
       "      <th>summary</th>\n",
       "      <th>clean_summary</th>\n",
       "      <th>label</th>\n",
       "      <th>keyphrases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blogandpostid/blog/post/50276-60f734ce80505100...</td>\n",
       "      <td>2021-07-20</td>\n",
       "      <td>News and Politics</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Golf</td>\n",
       "      <td>Trump Says Cheney Challengers Will Vie For His...</td>\n",
       "      <td>trump says cheney challengers vie endorsement ...</td>\n",
       "      <td>18</td>\n",
       "      <td>anti-trump rep. liz cheney, cheney challengers...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               natid    pub_date  \\\n",
       "0  blogandpostid/blog/post/50276-60f734ce80505100...  2021-07-20   \n",
       "\n",
       "            category   tier1 tier2  \\\n",
       "0  News and Politics  Sports  Golf   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Trump Says Cheney Challengers Will Vie For His...   \n",
       "\n",
       "                                       clean_summary  label  \\\n",
       "0  trump says cheney challengers vie endorsement ...     18   \n",
       "\n",
       "                                          keyphrases  \n",
       "0  anti-trump rep. liz cheney, cheney challengers...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last3_new_kps.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b36a3555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anti-trump rep. liz cheney, cheney challengers, rep. bennie thompson, rep. jamie raskin, wyoming state sen. anthony bouchard, sen. lisa murkowski, former president donald trump, one anti-cheney candidate, republican challenging rep. anthony gonzalez, house speaker nancy pelosi, new jersey golf club\n",
      "target black friday deals, black friday couch deals rove concepts, allmoderns black friday sale, hayneedles black friday sale, ballards black friday sale, macys black friday couch deals macys, pottery barns black friday sale\n"
     ]
    }
   ],
   "source": [
    "print(last3_new_kps.head(1)['keyphrases'][0])\n",
    "print(last3_new_kps.tail(1)['keyphrases'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52ef6158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11046, 9)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_kps = pd.concat([bq_kps, new_kps, last3_new_kps])\n",
    "all_kps.drop_duplicates('natid', keep='first', inplace=True)\n",
    "all_kps.reset_index(drop=True, inplace=True)\n",
    "all_kps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76fa969a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10078, 8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.natid.isin(all_kps.natid)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45acf9c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[~test.natid.isin(all_kps.natid)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94386b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>natid</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>category</th>\n",
       "      <th>tier1</th>\n",
       "      <th>tier2</th>\n",
       "      <th>summary</th>\n",
       "      <th>clean_summary</th>\n",
       "      <th>label</th>\n",
       "      <th>keyphrases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blogandpostid/blog/post/50808-607eda2d97a5b000...</td>\n",
       "      <td>2021-04-20</td>\n",
       "      <td>Personal Finance</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Real Estate Renting and Leasing</td>\n",
       "      <td>WeWork To Accept Crypto—And Will Pay Its Landl...</td>\n",
       "      <td>wework accept crypto pay landlords crypto. top...</td>\n",
       "      <td>7</td>\n",
       "      <td>elon musks tesla, cryptocurrencies, private in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               natid    pub_date  \\\n",
       "0  blogandpostid/blog/post/50808-607eda2d97a5b000...  2021-04-20   \n",
       "\n",
       "           category        tier1                            tier2  \\\n",
       "0  Personal Finance  Real Estate  Real Estate Renting and Leasing   \n",
       "\n",
       "                                             summary  \\\n",
       "0  WeWork To Accept Crypto—And Will Pay Its Landl...   \n",
       "\n",
       "                                       clean_summary  label  \\\n",
       "0  wework accept crypto pay landlords crypto. top...      7   \n",
       "\n",
       "                                          keyphrases  \n",
       "0  elon musks tesla, cryptocurrencies, private in...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_kps.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11b27bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10078, 9)\n"
     ]
    }
   ],
   "source": [
    "train_kps = pd.merge(train, \n",
    "                     all_kps[['natid', 'keyphrases']], \n",
    "                     how='left', \n",
    "                     on='natid')\n",
    "print(train_kps.shape)\n",
    "# print(train_kps.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eccd083c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1258, 9)\n"
     ]
    }
   ],
   "source": [
    "test_kps = pd.merge(test, \n",
    "                     all_kps[['natid', 'keyphrases']], \n",
    "                     how='left', \n",
    "                     on='natid')\n",
    "print(test_kps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "caf80971",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kps.to_csv(\"./data/mnet_train_keyphrase.csv\", index=False)\n",
    "\n",
    "train_kps.to_pickle(\"./data/mnet_train_keyphrase.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d31d70f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kps.to_csv(\"./data/mnet_test_keyphrase.csv\", index=False)\n",
    "\n",
    "test_kps.to_pickle(\"./data/mnet_test_keyphrase.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea3f894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1c629b4",
   "metadata": {},
   "source": [
    "* Testing files to make sure no errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0ea6fb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10078, 9)\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "train_csv = pd.read_csv(\"./data/mnet_train_keyphrase.csv\")\n",
    "print(train_csv.shape)\n",
    "print(train_csv.duplicated().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "88fbaa1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'college degrees, new jobs, upward mobility opportunities, college education, college proposition, upward jump, increasing opportunities, economic research, surveyed employers, stale researchers, new working paper, better benefits, few compelling data, qualified applicants, lingering doubts, little trouble, new report, employment and wage data, new paper'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.tail(1)['keyphrases'][10077]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b423d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10078, 9)\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "train_pkl = pd.read_pickle(\"./data/mnet_train_keyphrase.pkl\")\n",
    "print(train_pkl.shape)\n",
    "print(train_pkl.duplicated('natid').any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b451be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'college degrees, new jobs, upward mobility opportunities, college education, college proposition, upward jump, increasing opportunities, economic research, surveyed employers, stale researchers, new working paper, better benefits, few compelling data, qualified applicants, lingering doubts, little trouble, new report, employment and wage data, new paper'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pkl.tail(1)['keyphrases'][10077]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b4eaa3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10078, 9)\n",
      "(0, 9)\n",
      "(10078, 9)\n",
      "(10078, 9)\n",
      "(10078, 9)\n",
      "(10078, 9)\n",
      "(10078, 9)\n",
      "(10078, 9)\n",
      "Series([], Name: keyphrases, dtype: object)\n",
      "2021-04-20\n",
      "2021-04-20\n",
      "False\n",
      "elon musks tesla, cryptocurrencies, private investment, l ast week, nasdaq listing, latest payment app, memberships, mainstream acceptance, forbes) wework, usd coin, landlords, spac deal, wework membership\n",
      "elon musks tesla, cryptocurrencies, private investment, l ast week, nasdaq listing, latest payment app, memberships, mainstream acceptance, forbes) wework, usd coin, landlords, spac deal, wework membership\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(train_csv[train_csv.natid == train_pkl.natid].shape)\n",
    "print(train_csv[train_csv.pub_date == train_pkl.pub_date].shape)\n",
    "print(train_csv[train_csv.category == train_pkl.category].shape)\n",
    "print(train_csv[train_csv.tier1 == train_pkl.tier1].shape)\n",
    "print(train_csv[train_csv.tier2 == train_pkl.tier2].shape)\n",
    "print(train_csv[train_csv.summary == train_pkl.summary].shape)\n",
    "print(train_csv[train_csv.clean_summary == train_pkl.clean_summary].shape)\n",
    "print(train_csv[train_csv.label == train_pkl.label].shape)\n",
    "print(train_csv[train_csv.keyphrases == train_pkl.label].keyphrases)\n",
    "\n",
    "print(train_csv.pub_date[0])\n",
    "print(train_pkl.pub_date[0])\n",
    "\n",
    "print(train_csv.pub_date[0] == train_pkl.pub_date[0])\n",
    "\n",
    "print(train_csv.keyphrases[0])\n",
    "print(train_pkl.keyphrases[0])\n",
    "\n",
    "print(train_csv.keyphrases[0] == train_pkl.keyphrases[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74df2d61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6255eb62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-6.m79",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m79"
  },
  "kernelspec": {
   "display_name": "multi_labels",
   "language": "python",
   "name": "multi_labels"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
